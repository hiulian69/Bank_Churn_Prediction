{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RarNoE4PSXyr"
   },
   "source": [
    "# Bank data analysis\n",
    "\n",
    "The goal of your project is to create a robust classifier and use the data, where you will build a model that will recognize whether specific client will leave/unsubscribe the bank services.\n",
    "Make feature engineering but also try differnet models in order to get as much accuracy as possible.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfCA9MCqxs55"
   },
   "source": [
    "## Dataset Info\n",
    "\n",
    "* CLIENTNUM\n",
    "  - Client number. Unique identifier for the customer holding the account\n",
    "\n",
    "* Attrition_Flag (This is your target variable!)\n",
    "  - Internal event (customer activity) variable - if the account is closed then 1 else 0\n",
    "\n",
    "* Customer_Age\n",
    "  - Demographic variable - Customer's Age in Years\n",
    "\n",
    "* Gender\n",
    "  - Demographic variable - M=Male, F=Female\n",
    "\n",
    "* Dependent_count\n",
    "  - Demographic variable - Number of dependents\n",
    "\n",
    "* Education_Level\n",
    "  - Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n",
    "\n",
    "\n",
    "* Marital_Status\n",
    "  - Demographic variable - Married, Single, Divorced, Unknown\n",
    "\n",
    "* Income_Category\n",
    "  - Demographic variable - Annual Income Category of the account holder (< $40K, $40K - 60K, $60K - $80K, $80K-$120K, > $120K, Unknown)\n",
    "\n",
    "\n",
    "* Card_Category\n",
    "  - Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n",
    "\n",
    "* Months_on_book\n",
    "  - Period of relationship with bank\n",
    "\n",
    "\n",
    "* Total_Relationship_Count\n",
    "  - Total no. of products held by the customer\n",
    "\n",
    "* Months_Inactive_12_mon\n",
    "  - No. of months inactive in the last 12 months\n",
    "\n",
    "* Contacts_Count_12_mon\n",
    "  - No. of Contacts in the last 12 months\n",
    "\n",
    "* Credit_Limit\n",
    "  - Credit Limit on the Credit Card\n",
    "\n",
    "* Total_Revolving_Bal\n",
    "  - Total Revolving Balance on the Credit Card\n",
    "\n",
    "* Avg_Open_To_Buy\n",
    "  - Open to Buy Credit Line (Average of last 12 months)\n",
    "\n",
    "* Total_Amt_Chng_Q4_Q1\n",
    "  - Change in Transaction Amount (Q4 over Q1)\n",
    "\n",
    "* Total_Trans_Amt\n",
    "  - Total Transaction Amount (Last 12 months)\n",
    "\n",
    "* Total_Trans_Ct\n",
    "  - Total Transaction Count (Last 12 months)\n",
    "\n",
    "* Total_Ct_Chng_Q4_Q1\n",
    "  - Change in Transaction Count (Q4 over Q1)\n",
    "\n",
    "* Avg_Utilization_Ratio\n",
    "  - Average Card Utilization Ratio\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u823cXPI0QNc"
   },
   "source": [
    "# Working Plan\n",
    "\n",
    "\n",
    "\n",
    "1. Phase 1 : Dataset\n",
    "    * Team Planning\n",
    "    * Full git project Integration\n",
    "    * General Project Research\n",
    "    * Dataset Preparation\n",
    "    * Dataset Feature Engineering\n",
    "\n",
    "2. Phase 2 : Training\n",
    "    * Make Research about your model\n",
    "    * Compose your model (try different models) \n",
    "    * Ping Pong phase with Dataset feature engineers\n",
    "    * Generate more data if needed\n",
    "    * Fine tunning of your model\n",
    "\n",
    "3. Phase 3 : Deployment\n",
    "    * Perform benchmark (precision/recall), ROC curve\n",
    "    * Model Deploy (Git)\n",
    "    * Write git Readme.md file\n",
    "    * Receive Feedback from PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Xj5WSaLYSXys"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ChurnPrediction/churn-prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>772366833</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>710638233</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>2186</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>0.804</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>716506083</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0.819</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>717406983</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>714337233</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10388.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>8427.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0      768805383  Existing Customer            45      M                3   \n",
       "1      818770008  Existing Customer            49      F                5   \n",
       "2      713982108  Existing Customer            51      M                3   \n",
       "3      769911858  Existing Customer            40      F                4   \n",
       "4      709106358  Existing Customer            40      M                3   \n",
       "...          ...                ...           ...    ...              ...   \n",
       "10122  772366833  Existing Customer            50      M                2   \n",
       "10123  710638233  Attrited Customer            41      M                2   \n",
       "10124  716506083  Attrited Customer            44      F                1   \n",
       "10125  717406983  Attrited Customer            30      M                2   \n",
       "10126  714337233  Attrited Customer            43      F                2   \n",
       "\n",
       "      Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0         High School        Married     $60K - $80K          Blue   \n",
       "1            Graduate         Single  Less than $40K          Blue   \n",
       "2            Graduate        Married    $80K - $120K          Blue   \n",
       "3         High School        Unknown  Less than $40K          Blue   \n",
       "4          Uneducated        Married     $60K - $80K          Blue   \n",
       "...               ...            ...             ...           ...   \n",
       "10122        Graduate         Single     $40K - $60K          Blue   \n",
       "10123         Unknown       Divorced     $40K - $60K          Blue   \n",
       "10124     High School        Married  Less than $40K          Blue   \n",
       "10125        Graduate        Unknown     $40K - $60K          Blue   \n",
       "10126        Graduate        Married  Less than $40K        Silver   \n",
       "\n",
       "       Months_on_book  ...  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0        3.900000e+01  ...                       1                      3   \n",
       "1        4.400000e+01  ...                       1                      2   \n",
       "2        3.600000e+01  ...                       1                      0   \n",
       "3        3.400000e+01  ...                       4                      1   \n",
       "4        2.100000e+01  ...                       1                      0   \n",
       "...               ...  ...                     ...                    ...   \n",
       "10122    4.000000e+01  ...                       2                      3   \n",
       "10123    2.500000e+01  ...                       2                      3   \n",
       "10124    3.600000e+01  ...                       3                      4   \n",
       "10125    2.147484e+09  ...                       3                      3   \n",
       "10126    2.500000e+01  ...                       2                      4   \n",
       "\n",
       "       Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "0           12691.0                  777          11914.0   \n",
       "1            8256.0                  864           7392.0   \n",
       "2            3418.0                    0           3418.0   \n",
       "3            3313.0                 2517            796.0   \n",
       "4            4716.0                    0           4716.0   \n",
       "...             ...                  ...              ...   \n",
       "10122        4003.0                 1851           2152.0   \n",
       "10123        4277.0                 2186           2091.0   \n",
       "10124        5409.0                    0           5409.0   \n",
       "10125        5281.0                    0           5281.0   \n",
       "10126       10388.0                 1961           8427.0   \n",
       "\n",
       "       Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0                     1.335             1144              42   \n",
       "1                     1.541             1291              33   \n",
       "2                     2.594             1887              20   \n",
       "3                     1.405             1171              20   \n",
       "4                     2.175              816              28   \n",
       "...                     ...              ...             ...   \n",
       "10122                 0.703            15476             117   \n",
       "10123                 0.804             8764              69   \n",
       "10124                 0.819            10291              60   \n",
       "10125                 0.535             8395              62   \n",
       "10126                 0.703            10294              61   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0                    1.625                  0.061  \n",
       "1                    3.714                  0.105  \n",
       "2                    2.333                  0.000  \n",
       "3                    2.333                  0.760  \n",
       "4                    2.500                  0.000  \n",
       "...                    ...                    ...  \n",
       "10122                0.857                  0.462  \n",
       "10123                0.683                  0.511  \n",
       "10124                0.818                  0.000  \n",
       "10125                0.722                  0.000  \n",
       "10126                0.649                  0.189  \n",
       "\n",
       "[10127 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attrition_Flag': ['Existing Customer', 'Attrited Customer'],\n",
       " 'Gender': ['M', 'F'],\n",
       " 'Education_Level': ['High School',\n",
       "  'Graduate',\n",
       "  'Uneducated',\n",
       "  'Unknown',\n",
       "  'College',\n",
       "  'Post-Graduate',\n",
       "  'Doctorate'],\n",
       " 'Marital_Status': ['Married', 'Single', 'Unknown', 'Divorced'],\n",
       " 'Income_Category': ['$60K - $80K',\n",
       "  'Less than $40K',\n",
       "  '$80K - $120K',\n",
       "  '$40K - $60K',\n",
       "  '$120K +',\n",
       "  'Unknown'],\n",
       " 'Card_Category': ['Blue', 'Gold', 'Silver', 'Platinum']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{column: list(data[column].unique()) for column in data.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLIENTNUM',\n",
       " 'Attrition_Flag',\n",
       " 'Customer_Age',\n",
       " 'Gender',\n",
       " 'Dependent_count',\n",
       " 'Education_Level',\n",
       " 'Marital_Status',\n",
       " 'Income_Category',\n",
       " 'Card_Category',\n",
       " 'Months_on_book',\n",
       " 'Total_Relationship_Count',\n",
       " 'Months_Inactive_12_mon',\n",
       " 'Contacts_Count_12_mon',\n",
       " 'Credit_Limit',\n",
       " 'Total_Revolving_Bal',\n",
       " 'Avg_Open_To_Buy',\n",
       " 'Total_Amt_Chng_Q4_Q1',\n",
       " 'Total_Trans_Amt',\n",
       " 'Total_Trans_Ct',\n",
       " 'Total_Ct_Chng_Q4_Q1',\n",
       " 'Avg_Utilization_Ratio']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_column = list(data.columns)\n",
    "list_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcK1sU4iSXyw"
   },
   "source": [
    "## 1. Data preprocessing, normalization, missing data, categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def one_hot_encode(df, column, prefix):# found this function which is b\n",
    "    df = df.copy()\n",
    "    dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(column, axis=1)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, scale=False, one_hot=False , age_groupe = False ):\n",
    "    \n",
    "    #drop ID - has only unique values\n",
    "    df = df.drop('CLIENTNUM', axis=1)\n",
    "    \n",
    "    if age_groupe == True:\n",
    "        list_AgeGroup = [data]\n",
    "        for column in list_AgeGroup:\n",
    "            column.loc[column[\"Customer_Age\"] < 18,  'age_group'] = 18\n",
    "            column.loc[(column[\"Customer_Age\"] >= 19) & (column[\"Customer_Age\"] <= 29), 'age_group'] = 20\n",
    "            column.loc[(column[\"Customer_Age\"] >= 30) & (column[\"Customer_Age\"] <= 39), 'age_group'] = 30\n",
    "            column.loc[(column[\"Customer_Age\"] >= 40) & (column[\"Customer_Age\"] <= 49), 'age_group'] = 40\n",
    "            column.loc[(column[\"Customer_Age\"] >= 50) & (column[\"Customer_Age\"] <= 59), 'age_group'] = 50\n",
    "            column.loc[column[\"Customer_Age\"] >= 60, 'age_group'] = 60\n",
    "    \n",
    "    \n",
    "    # handle unknown values\n",
    "    df['Income_Category'] = df['Income_Category'].replace('Unknown', np.NaN)\n",
    "   \n",
    "    \n",
    "    # Fill ordinal missing values with modes ( Income_Category column)\n",
    "    df['Income_Category'] = df['Income_Category'].fillna('Less than $40K')\n",
    "    \n",
    "    # handle unknown values of marital status\n",
    "    df['Marital_Status'] = df['Marital_Status'].replace('Unknown', np.NaN)\n",
    "    \n",
    "    # Fill missing values with dominant value ( Marital_Status column)\n",
    "    df['Marital_Status'] = df['Marital_Status'].fillna(df['Marital_Status'].value_counts().index[0])\n",
    "\n",
    "    #Ordinal Variables Encoding\n",
    "\n",
    "    Income_Category_map = {\n",
    "    'Less than $40K' : 0,\n",
    "    '$40K - $60K'    : 1,\n",
    "    '$60K - $80K'    : 2,\n",
    "    '$80K - $120K'   : 3,\n",
    "    '$120K +'        : 4\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "    Card_Category_map = {\n",
    "    'Blue'     : 0,\n",
    "    'Silver'   : 1,\n",
    "    'Gold'     : 2,\n",
    "    'Platinum' : 3\n",
    "    }\n",
    "\n",
    "\n",
    "    Attrition_Flag_map = {\n",
    "    'Existing Customer' : 0,\n",
    "    'Attrited Customer' : 1\n",
    "    }\n",
    "\n",
    "    # Too many Unknown value to exclude it\n",
    "    Education_Level_map = {\n",
    "    'Uneducated'    : 0,\n",
    "    'High School'   : 1,\n",
    "    'College'       : 2,\n",
    "    'Graduate'      : 3,\n",
    "    'Post-Graduate' : 4,\n",
    "    'Doctorate'     : 5,\n",
    "    'Unknown'       : 6\n",
    "    }\n",
    "    \n",
    "    Gender_Map = {\n",
    "        'M' : 0,\n",
    "        'F' : 1\n",
    "    }\n",
    "\n",
    "    df.loc[:, 'Income_Category'] = df['Income_Category'].map(Income_Category_map)\n",
    "    df.loc[:, 'Attrition_Flag'] = df['Attrition_Flag'].map(Attrition_Flag_map)\n",
    "    df.loc[:, 'Education_Level'] = df['Education_Level'].map(Education_Level_map)\n",
    "    df.loc[:, 'Gender'] = df['Gender'].map(Gender_Map)\n",
    "    \n",
    "    #encoding using the function above creating + deleting old columns\n",
    "    if one_hot == True:\n",
    "        \n",
    "        df = one_hot_encode(df, 'Marital_Status', prefix='MS')\n",
    "        df = one_hot_encode(df, 'Card_Category', prefix='CC')\n",
    "    else:\n",
    "        df.loc[:, 'Card_Category'] = df['Card_Category'].map(Card_Category_map)\n",
    "    \n",
    "    # Label Encoder\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # the remaining categorical data are 'objects' as datatyes\n",
    "    categ = [x for x in df.columns if df[x].dtype == 'object']\n",
    "    \n",
    "    #fit_transform on each categorical column\n",
    "    for a in categ:\n",
    "        df.loc[:, a]=le.fit_transform(df.loc[:,a])\n",
    "        \n",
    "   \n",
    "    #X[\"Total_Trans_Ct_Categorical\"] = pd.cut(X.Total_Trans_Ct,bins = 16, labels = range(1,17)) \n",
    "    #X[\"Total_Trans_Amt_Categorical\"] =pd.cut(X.Total_Trans_Amt,bins = 16, labels = range(1,17))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    y = df.Attrition_Flag \n",
    "    X = df.drop('Attrition_Flag', axis=1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    #Scale X\n",
    "    if scale == True:\n",
    "        scaler = StandardScaler()\n",
    "        ro_sc = RobustScaler()\n",
    "        \n",
    "        \n",
    "        #X_ =X.loc[:,['Customer_Age', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Trans_Ct']]#variables to be scacled\n",
    "        #X = X.drop(['Customer_Age', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Trans_Ct' ], axis = 1) #drop from df\n",
    " \n",
    "        #X_ = pd.DataFrame(scaler.fit_transform(X_), columns=X_.columns)\n",
    "\n",
    "        X_ =X.loc[:,  ['Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']]\n",
    "        \n",
    "        X = X.drop([ 'Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'], axis= 1)\n",
    "    \n",
    "        X_ = pd.DataFrame(scaler.fit_transform(X_), columns=X_.columns)\n",
    "        \n",
    "        X = X.merge(X_, left_index = True, right_index = True)\n",
    "        \n",
    "        \n",
    "        X_2 = X.loc[:,['Credit_Limit', 'Total_Amt_Chng_Q4_Q1','Total_Trans_Amt' ]]\n",
    "        X = X.drop(['Credit_Limit',  'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt'], axis = 1)\n",
    "        \n",
    "        X_2 = pd.DataFrame(ro_sc.fit_transform(X_2), columns= X_2.columns)\n",
    "        X = X.merge(X_2, left_index = True, right_index = True)\n",
    "        #create bins for bimodal continious data\n",
    "    \n",
    "        X[\"Total_Trans_Ct_Categorical\"] = pd.cut(X.Total_Trans_Ct,bins = 16, labels = range(1,17)) \n",
    "        X[\"Total_Trans_Amt_Categorical\"] =pd.cut(X.Total_Trans_Amt,bins = 16, labels = range(1,17))\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED FUNCTION - set 2  paramaters to choose preferance of preprocessing \n",
    "# Set scale on TRUE to get scaled data\n",
    "# Set one_hot on True to get Marital Status and CardCategory one hot encoded\n",
    "\n",
    "#X, y = preprocess_data(data)\n",
    "#X, y = preprocess_data(data, scale=False , one_hot=True)\n",
    "X, y = preprocess_data(data, scale=True, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>MS_Divorced</th>\n",
       "      <th>MS_Married</th>\n",
       "      <th>MS_Single</th>\n",
       "      <th>CC_Blue</th>\n",
       "      <th>CC_Gold</th>\n",
       "      <th>CC_Platinum</th>\n",
       "      <th>CC_Silver</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct_Categorical</th>\n",
       "      <th>Total_Trans_Amt_Categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.473422</td>\n",
       "      <td>0.488971</td>\n",
       "      <td>-0.973895</td>\n",
       "      <td>3.834003</td>\n",
       "      <td>-0.775882</td>\n",
       "      <td>0.956476</td>\n",
       "      <td>2.627193</td>\n",
       "      <td>-1.065558</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.008486</td>\n",
       "      <td>-1.357340</td>\n",
       "      <td>12.608573</td>\n",
       "      <td>-0.616276</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>3.530702</td>\n",
       "      <td>-1.008702</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.426858</td>\n",
       "      <td>-0.445658</td>\n",
       "      <td>-1.911206</td>\n",
       "      <td>6.807864</td>\n",
       "      <td>-0.997155</td>\n",
       "      <td>-0.132863</td>\n",
       "      <td>8.149123</td>\n",
       "      <td>-0.778186</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.661686</td>\n",
       "      <td>-0.734100</td>\n",
       "      <td>-1.911206</td>\n",
       "      <td>6.807864</td>\n",
       "      <td>1.759686</td>\n",
       "      <td>-0.145198</td>\n",
       "      <td>2.934211</td>\n",
       "      <td>-1.055115</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.426858</td>\n",
       "      <td>-0.302868</td>\n",
       "      <td>-1.570365</td>\n",
       "      <td>7.509325</td>\n",
       "      <td>-0.997155</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>6.311404</td>\n",
       "      <td>-1.192419</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844455</td>\n",
       "      <td>-0.584929</td>\n",
       "      <td>2.221481</td>\n",
       "      <td>0.608119</td>\n",
       "      <td>0.678714</td>\n",
       "      <td>-0.064141</td>\n",
       "      <td>-0.144737</td>\n",
       "      <td>4.477664</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.255524</td>\n",
       "      <td>-0.591639</td>\n",
       "      <td>0.176440</td>\n",
       "      <td>-0.122745</td>\n",
       "      <td>0.856458</td>\n",
       "      <td>-0.031953</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>1.881648</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.426858</td>\n",
       "      <td>-0.226632</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>0.444305</td>\n",
       "      <td>-0.997155</td>\n",
       "      <td>0.101028</td>\n",
       "      <td>0.364035</td>\n",
       "      <td>2.472249</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.426858</td>\n",
       "      <td>-0.240713</td>\n",
       "      <td>-0.121795</td>\n",
       "      <td>0.041070</td>\n",
       "      <td>-0.997155</td>\n",
       "      <td>0.085991</td>\n",
       "      <td>-0.881579</td>\n",
       "      <td>1.738929</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979433</td>\n",
       "      <td>0.105372</td>\n",
       "      <td>-0.164400</td>\n",
       "      <td>-0.265557</td>\n",
       "      <td>-0.311572</td>\n",
       "      <td>0.685932</td>\n",
       "      <td>-0.144737</td>\n",
       "      <td>2.473409</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender  Education_Level  Income_Category  MS_Divorced  MS_Married  \\\n",
       "0           0                1                2            0           1   \n",
       "1           1                3                0            0           0   \n",
       "2           0                3                3            0           1   \n",
       "3           1                1                0            0           1   \n",
       "4           0                0                2            0           1   \n",
       "...       ...              ...              ...          ...         ...   \n",
       "10122       0                3                1            0           0   \n",
       "10123       0                6                1            1           0   \n",
       "10124       1                1                0            0           1   \n",
       "10125       0                3                1            0           1   \n",
       "10126       1                3                0            0           1   \n",
       "\n",
       "       MS_Single  CC_Blue  CC_Gold  CC_Platinum  CC_Silver  ...  \\\n",
       "0              0        1        0            0          0  ...   \n",
       "1              1        1        0            0          0  ...   \n",
       "2              0        1        0            0          0  ...   \n",
       "3              0        1        0            0          0  ...   \n",
       "4              0        1        0            0          0  ...   \n",
       "...          ...      ...      ...          ...        ...  ...   \n",
       "10122          1        1        0            0          0  ...   \n",
       "10123          0        1        0            0          0  ...   \n",
       "10124          0        1        0            0          0  ...   \n",
       "10125          0        1        0            0          0  ...   \n",
       "10126          0        0        0            0          1  ...   \n",
       "\n",
       "       Total_Revolving_Bal  Avg_Open_To_Buy  Total_Trans_Ct  \\\n",
       "0                -0.473422         0.488971       -0.973895   \n",
       "1                -0.366667        -0.008486       -1.357340   \n",
       "2                -1.426858        -0.445658       -1.911206   \n",
       "3                 1.661686        -0.734100       -1.911206   \n",
       "4                -1.426858        -0.302868       -1.570365   \n",
       "...                    ...              ...             ...   \n",
       "10122             0.844455        -0.584929        2.221481   \n",
       "10123             1.255524        -0.591639        0.176440   \n",
       "10124            -1.426858        -0.226632       -0.207005   \n",
       "10125            -1.426858        -0.240713       -0.121795   \n",
       "10126             0.979433         0.105372       -0.164400   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Credit_Limit  \\\n",
       "0                 3.834003              -0.775882      0.956476   \n",
       "1                12.608573              -0.616276      0.435477   \n",
       "2                 6.807864              -0.997155     -0.132863   \n",
       "3                 6.807864               1.759686     -0.145198   \n",
       "4                 7.509325              -0.997155      0.019618   \n",
       "...                    ...                    ...           ...   \n",
       "10122             0.608119               0.678714     -0.064141   \n",
       "10123            -0.122745               0.856458     -0.031953   \n",
       "10124             0.444305              -0.997155      0.101028   \n",
       "10125             0.041070              -0.997155      0.085991   \n",
       "10126            -0.265557              -0.311572      0.685932   \n",
       "\n",
       "       Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct_Categorical  \\\n",
       "0                  2.627193        -1.065558                           4   \n",
       "1                  3.530702        -1.008702                           3   \n",
       "2                  8.149123        -0.778186                           2   \n",
       "3                  2.934211        -1.055115                           2   \n",
       "4                  6.311404        -1.192419                           3   \n",
       "...                     ...              ...                         ...   \n",
       "10122             -0.144737         4.477664                          14   \n",
       "10123              0.298246         1.881648                           8   \n",
       "10124              0.364035         2.472249                           7   \n",
       "10125             -0.881579         1.738929                           7   \n",
       "10126             -0.144737         2.473409                           7   \n",
       "\n",
       "       Total_Trans_Amt_Categorical  \n",
       "0                                1  \n",
       "1                                1  \n",
       "2                                2  \n",
       "3                                1  \n",
       "4                                1  \n",
       "...                            ...  \n",
       "10122                           14  \n",
       "10123                            8  \n",
       "10124                            9  \n",
       "10125                            8  \n",
       "10126                            9  \n",
       "\n",
       "[10127 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test,train,y_test = train_test_split(X, y, test_size=0.2, random_state=42) #Not used because of the Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.946 (0.007)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate random forest algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Process data for Tree Based Alg.\n",
    "X, y = preprocess_data(data, scale=False, one_hot=False )\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=8, random_state=1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f1QIHDpbSXy0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905 (0.008)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# We reprocess data in favour for the classification algorithm\n",
    "X, y = preprocess_data(data , scale =True, one_hot= True)\n",
    "\n",
    "LogReg_clf = LogisticRegression(random_state = 1)\n",
    "\n",
    "#LogReg_clf.fit(X y)\n",
    "\n",
    "#y_pred = LogReg_clf.predict(X_test)\n",
    "\n",
    "\n",
    "n_scores = cross_val_score(LogReg_clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrest > Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DATA AUGMENTATION Balaceing data( I think )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b30b3e8afe75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBorderlineSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "def smote(x, y):\n",
    "    # Synthetic Minority Over-samping Technique\n",
    "    # \n",
    "    # sampling_strategy: determines the portion of samples to \n",
    "    #                    generate with respect to the majority class\n",
    "    # k_neighbors : number of neighbors to be considered for each sample\n",
    "    \n",
    "    # For this example, only 1% of minoirty samples are considered\n",
    "    k_neighbors = math.ceil(sum(y) * 0.01)\n",
    "      \n",
    "    smote = SMOTE(sampling_strategy=1, \n",
    "                  k_neighbors=k_neighbors)\n",
    "    x, y = smote.fit_resample(x, y)\n",
    "    \n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_data(data, scale=True, one_hot=True)\n",
    "X, y = smote(X, y)\n",
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Check of the target has been balanced\n",
    "sns.countplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# We reprocess data in favour for the classification algorithm\n",
    "X, y = preprocess_data(data , scale =True, one_hot= True)\n",
    "\n",
    "AdaBoost = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "n_scores = cross_val_score(AdaBoost, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiazHmxRSXy0"
   },
   "source": [
    "## 2. Feature Anaysis, Extraction & Selection\n",
    "(you may need to perform feature selection after creating default models and compare to them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92THQSXGSXy3"
   },
   "source": [
    "## 3. Classification models\n",
    "- classical classification models\n",
    "- deep neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ve5_cjilSXy4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGyhoU96SXy7"
   },
   "source": [
    "## 4. Evaluation and comparisons, various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0_vsmimSXy8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4TYzMqQSXy_"
   },
   "source": [
    "## 5. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5DpSTA-SXy_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1Uyu5APSXzD"
   },
   "source": [
    "## 6. Final evaluations and comparisons\n",
    "- the best model - analyze it in details, evaluate it with different train/test splits. Is it robust enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJYe6t-oSXzD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yo2Rs_5SXzG"
   },
   "source": [
    "## 7. Discussion, Concusions, Future improvements\n",
    "- which features are the most important\n",
    "- how will you explain the model to the management of the bank\n",
    "- how much benefit/improvement should the bank expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bank_template_Churn_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
